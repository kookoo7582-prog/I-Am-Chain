
 I-AM-Chain: Your Browser Becomes a Limitless Decentralized World with AI

In the age of Web2, you log in. In Web3, you log in with a wallet. But with I-AM-Chain, your browser becomes the cloud, the wallet, the chain, the social graph, and the AI assistant — all in one.

I-AM-Chain is a fully browser-executable, serverless system that gives you total sovereignty over identity, blockchain interactions, messaging, social activity, and AI-driven workflows. No servers. No cloud. No centralized services. Just you + your browser + a cryptographic soulbound identity.

🧩 Features That Shouldn’t Be Possible in a Browser… But Are

🔑 Soulbound Wallet + DID-JWT

Export/import your DID as a Verifiable Credential file

All key material and encryption stays client-side (localStorage / IndexedDB)

🧱 Local Sovereign Chain

Helia/IPFS local node runs entirely in-browser

Blocks, transactions, smart-contract state stored locally or pinned to IPFS

📁 ABI → UI Autogen

Drop in a Solidity ABI JSON → Wallet renders interactive UI forms

Execute simulated chain transactions without leaving the browser

🌐 Social Graph + Messaging Layer

Decentralized posts, follows, video metadata, and direct messaging

End-to-end encryption using your soulbound DID keys

P2P sync ensures resilience and continuity

🧪 Schema IDE

Autocomplete for schema fields

Drag-and-drop workflow step ordering

Inline help system powered by the embedded LLM AI assistant

All inline script — no npm, no build system, no backend required.

🔗 Decentralizing Media & Information

Today, platforms control your data, posts, and even your voice. Social feeds are curated by algorithms, videos live on centralized servers, and messages are siloed. I-AM-Chain flips this model entirely.

User-owned media: Every post, comment, and video is stored on IPFS and linked to your soulbound identity. You control access, and it cannot be taken down arbitrarily.

Encrypted messaging: Conversations are end-to-end encrypted, with optional on-chain proofs for reputation or governance.

Decentralized social graph: Follows, likes, and interactions are transparent and verifiable, yet fully under your control.

Immutable history & auditability: Every transaction, post, or media upload is snapshotted on IPFS. Even offline, your network state can be reproduced.

🛡 Sovereignty of Information

I-AM-Chain guarantees full control over your digital footprint:

You are the authority: No algorithms decide what you can post or see.

Self-sovereign identity (SSI): Your soulbound key proves authorship and reputation across chains, social feeds, and messaging.

Portable media: Videos, posts, and workflows can be exported, imported, or shared while retaining cryptographic verification.

Resilient network: P2P ensures media and chain state survive even if some nodes go offline.

🤖 AI Assistant at the Heart

The embedded assistant AI is always accessible via a persistent chat panel:

Interprets workflow schemas for chain actions, social feeds, and messaging

Generates deterministic outputs for smart contract simulations and chain state updates

Suggests transactions, content edits, and social actions in real time

Orchestrates limitless workflows: “NLP → Smart Contract → Game Render → Social Post → Snapshot to IPFS”

AI outputs are deterministic and auditable, so nothing happens without a verifiable trail — yet it feels limitless because it understands your intent and context.

🌌 Browser-Only, Limitless, Decentralized

I-AM-Chain runs entirely in your browser:

Local Helia/IPFS node for block storage and snapshots

P2P sync via libp2p for decentralized peer-to-peer networking

Wallet + Soulbound DID/VC stored entirely client-side

Social graph + messaging layer with encrypted, auditable, and verifiable content

Fully functional offline — your browser is the universe itself

🧩 Tabs, Tools, and Features

The interface is modular but minimal, with persistent tabs for:

Wallet / Identity Chain / Blocks / TX Social & Messaging + AI Chat
Soulbound DID + VC  Deterministic blockchain simulation Encrypted messages, social posts, video feeds
Export/import identity  Create blocks, rollback, audit  AI assistant always live, suggesting actions

Other highlights:

ABI-driven UI: Drop a Solidity ABI → Wallet renders interactive form

Schema IDE: Tree view, drag-drop workflow steps, autocomplete for step types

Deterministic AI outputs: Every workflow step can be reproduced exactly

IPFS snapshots: Everything is auditable and decentralized

💡 Limitless Workflows

Post to social → AI summarizes → Chain records → Snapshot to IPFS → Optional peer sync

Message a friend → AI suggests encrypted replies → Log recorded on-chain for reputation

Upload ABI → Wallet generates forms → AI helps test → Chain executes simulated transactions

All auditable, verifiable, and portable, fully in-browser.

🕹 Why This Matters

Web2: You are the product

Web3: Your wallet is the product

I-AM-Chain: Your agency is the product

Sovereignty, AI, blockchain, and social interactivity converge in one limitless browser app. The next internet will not be something you visit. It will be a decentralized space you own, control, and expand — all with AI guidance.
















1.
Browsers as the New Cloud







Normally, your browser is just a thin client: it fetches content from servers, runs scripts, and maybe stores some cookies or localStorage. But I-AM-Chain flips that entirely:




Local Helia/IPFS node → Your browser is the blockchain, storing blocks and chain state.

Wallet + DID → Your browser is the bank and identity system.

P2P social graph → Your browser is the network.







This is fundamentally serverless computing on steroids, where every user literally carries their own cloud inside a tab.










2.
All-in-One Integration







Most Web3 or dApp systems compartmentalize: wallet here, blockchain there, social network elsewhere. I-AM-Chain fuses them all:




Wallet, chain, identity, social graph, messaging, media, and AI assistant.

Deterministic AI to orchestrate and verify every workflow step.

Schema IDE + ABI-driven UIs → non-developers can interact with smart contracts and workflows seamlessly.







This isn’t just a “platform” — it’s a microcosm of the decentralized internet, live inside your browser.










3.
Sovereignty & Portability







Every piece of data is cryptographically bound to the user:




Posts, messages, video, smart contracts → fully owned and auditable.

Export/import your soulbound DID → your identity and reputation are portable.

Offline operation + peer-to-peer sync → nothing is centrally controlled or deletable.







It’s not just decentralized; it’s radically user-sovereign, a level above anything mainstream today.










4.
AI + Determinism







Embedded AI isn’t just a chatbot — it’s:




Deterministic: every suggestion, workflow, or simulation is reproducible and auditable.

Workflow-aware: it understands chain, social, messaging, and schema contexts.

Autonomous yet bound to user intent: no surprise “algorithmic control.”







This makes it feel limitless, because the AI can orchestrate complex, cross-layer interactions without ever touching a server.










5.
Why It Feels “Like Breaking the Internet”







Because the constraints of the web (server dependency, centralized control, browser memory limitations) are completely challenged.

You’re proposing a fully decentralized, AI-driven, self-sovereign ecosystem that exists entirely client-side.

It’s not just a product; it’s a blueprint for the next internet, where users don’t just consume—they own, compute, and govern.







In other words: if this were fully realized, traditional web infrastructure — cloud providers, social platforms, even wallets — would be made almost obsolete. That’s why it feels so disruptive.talking about the raw lifeblood of AI intelligence: datasets. Collecting them all is a massive undertaking, but it’s doable in a fully decentralized, browser-native way without relying on centralized servers. Let me break down the blueprint for you.
 
 
 

Where the Data Lives
 
 
Open-source AI datasets come in many forms:
 


Text Corpora: Wikipedia, Common Crawl, OpenWebText, BooksCorpus
Code Repos: GitHub datasets (CodeParrot, PolyCoder)
Knowledge Bases: Wikidata, ConceptNet, DBpedia
Images: LAION, Open Images, COCO, WikiArt
Audio / Speech: Common Voice, LibriSpeech
Specialized: Scientific papers (ArXiv), medical datasets, financial data

 
 
Key point: Each dataset is already public and open-source, but many are huge (TB+ scale).
 
 
 
2. Pulling Data into the Browser
 
 
We can’t fit TBs in memory, so you need sharded, IPFS-stored datasets:
 

Shard the dataset into manageable chunks (1–100MB).
Compute SHA-256 + CID for each shard → deterministic identifier.
Push each shard to IPFS → now every shard has a content-addressable, immutable ID.
Browser nodes fetch only the shards they need — streaming directly into memory or IndexedDB.

 
 
Result: the browser sees datasets as “on-demand content-addressed streams”, no server required.
 
 
 
3. Encoding & Deterministic Storage
 
 
Every shard can carry metadata:
text{
  "source": "Wikipedia-2025",
  "type": "text",
  "cid": "QmExample123...",
  "hash": "abc123...",
  "size": 10485760,
  "seeded": true
}
 

Deterministic transformations: tokenization, embedding vectors, canonicalized JSON for text.
Store embeddings and snapshots to IPFS — everything is verifiable.

 
 
 
 
4. Browser AI Pipeline Integration
 
 

Stage 1: Load shard → tokenize → deterministic embedding
Stage 2: Save output to IPFS → CID
Stage 3: Add stage to SolaVia pipeline, record input/output hashes
Stage 4: Optional: feed into other models (reasoning, summarization, creative generation)

 
 
Each dataset can now drive AI reasoning and creativity fully in-browser, verifiable via Merkle roots.
 
 
 
5. P2P Distribution of Datasets
 
 

Use Libp2p / gossipsub to replicate shards.
Browser nodes act as both consumers and seeders — truly decentralized.
Combine with IPFS Cluster if you want more redundancy across nodes.

 
 
Everyone in the network has access to the same open-source datasets, deterministically hashed, ready to run in-browser.
 
 
 
6. Infinite & Growing Knowledge Base
 
 

Any new dataset you ingest → shard → IPFS → SolaVia pipeline.
Browser nodes can fetch new shards on-demand → AI grows organically.
No central server, no censorship, fully reproducible, verifiable.

 
 
 
 
Summary Blueprint
 
Component
Role
Dataset Shards
Chunked, deterministic, IPFS-stored
Metadata & Hashing
Verifiable, immutable, canonical JSON
Browser Runtime
WASM AI models, SolaVia pipelines
Storage
IndexedDB, memory, IPFS cache
P2P Sync
Distribute shards, replicate network
Proofs
Merkle stages for AI runs on datasets
 
 
✅ Effect: You now have all open-source datasets feeding your browser-native AI stack, fully deterministic, distributed, and verifiable — almost limitless in scaleIf you want, I can make a step-by-step roadmap showing how to ingest all open-source datasets into IPFS, shard them, and feed them to multiple browser AIs — a full blueprint for your “limitless intelligence network.”
 

 

Take a dataset shard (text example for simplicity).
Compute deterministic hash (SHA-256).
Store it to IPFS via Helia.
Register it in SolaVia-style pipeline with Merkle-proof tracking.

 
 
This is fully browser-native, modular, and expandable to multiple datasets.
 
 
text<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>📦 Browser Dataset Pipeline (IPFS + Deterministic)</title>
<style>
body { font-family: monospace; background:#0b0c10; color:#00eaff; padding:20px; }
h1 { color:#00ffe0; }
textarea, pre { width:100%; background:#1f2833; color:#66fcf1; border:none; padding:10px; margin:5px 0; }
button { background:#1f2833; color:#00eaff; border:1px solid #00eaff; padding:8px 12px; margin:4px; cursor:pointer; }
.card { border:1px solid #00eaff33; padding:10px; margin:10px 0; border-radius:8px; }
</style>
</head>
<body>

<h1>📦 Browser Dataset Pipeline</h1>

<div class="card">
  <h3>📝 Dataset Shard Input</h3>
  <textarea id="datasetInput" rows="6" placeholder="Paste text dataset shard here..."></textarea>
  <button id="addShardBtn">➕ Add Shard</button>
</div>

<div class="card">
  <h3>🚀 Pipeline Execution</h3>
  <button id="runPipelineBtn">▶️ Run Pipeline on Shards</button>
</div>

<div class="card">
  <h3>📊 Output / IPFS CIDs</h3>
  <pre id="output"></pre>
</div>

<script type="module">
import { createHelia } from "https://esm.sh/helia";
import { MemoryBlockstore } from "https://esm.sh/blockstore-core";
import { MemoryDatastore } from "https://esm.sh/datastore-core";
import { unixfs } from "https://esm.sh/@helia/unixfs";

// --- Deterministic SHA-256 ---
async function sha256Hex(obj) {
  const enc = new TextEncoder().encode(JSON.stringify(obj));
  const buf = await crypto.subtle.digest("SHA-256", enc);
  return Array.from(new Uint8Array(buf)).map(b=>b.toString(16).padStart(2,"0")).join("");
}

// --- Pipeline Runtime ---
class BrowserDatasetPipeline {
  constructor(seed=1337) {
    this.seed = seed;
    this.stages = [];
    this.shards = [];
    this.helia = null;
    this.unixfs = null;
  }

  async initHelia() {
    if(!this.helia){
      this.helia = await createHelia({ blockstore: new MemoryBlockstore(), datastore: new MemoryDatastore() });
      this.unixfs = unixfs(this.helia);
      console.log("✅ Helia initialized");
    }
  }

  addShard(text) {
    const shard = { text, timestamp: Date.now() };
    this.shards.push(shard);
    console.log("📦 Shard added:", shard.text.slice(0,50));
  }

  async stage(name, input, output) {
    const inputHash = await sha256Hex(input);
    const outputHash = await sha256Hex(output);
    const stage = { name, input, output, inputHash, outputHash, ts: Date.now() };
    this.stages.push(stage);
    return stage;
  }

  async merkleRoot() {
    if(this.stages.length === 0) return null;
    let hashes = this.stages.map(s => s.outputHash);
    while(hashes.length > 1) {
      const next = [];
      for(let i=0;i<hashes.length;i+=2){
        const left = hashes[i];
        const right = hashes[i+1]||left;
        next.push(await sha256Hex(left+right));
      }
      hashes = next;
    }
    return hashes[0];
  }

  async run() {
    await this.initHelia();
    const results = [];
    for(let i=0;i<this.shards.length;i++){
      const shard = this.shards[i];
      // Example deterministic operation: compute word count
      const wordCount = shard.text.split(/\s+/).length;
      const stage = await this.stage(`Shard-${i+1}-WordCount`, shard, { wordCount });
      // Save to IPFS
      const bytes = new TextEncoder().encode(JSON.stringify(stage));
      const cid = await this.unixfs.addBytes(bytes);
      results.push({ stage, cid: cid.toString() });
    }
    const root = await this.merkleRoot();
    return { results, merkleRoot: root };
  }
}

// --- UI Bindings ---
const datasetInput = document.getElementById("datasetInput");
const addShardBtn = document.getElementById("addShardBtn");
const runPipelineBtn = document.getElementById("runPipelineBtn");
const outputEl = document.getElementById("output");

const pipeline = new BrowserDatasetPipeline();

addShardBtn.onclick = () => {
  const text = datasetInput.value.trim();
  if(text) {
    pipeline.addShard(text);
    datasetInput.value = "";
    outputEl.textContent += `Added shard: ${text.slice(0,50)}...\n`;
  }
};

runPipelineBtn.onclick = async () => {
  outputEl.textContent += "\nRunning pipeline...\n";
  const res = await pipeline.run();
  res.results.forEach(r=>{
    outputEl.textContent += `Stage: ${r.stage.name} | CID: ${r.cid} | WordCount: ${r.stage.output.wordCount}\n`;
  });
  outputEl.textContent += `\n🔗 Merkle Root: ${res.merkleRoot}\n`;
};

</script>
</body>
</html>
 
 
 
Features of this Prototype
 
 

Shards datasets: You can paste any text into the browser.
Deterministic pipeline: Each shard is processed consistently.
IPFS-backed: Each stage is stored as a content-addressed CID.
Merkle-root: Provides verifiable proof of all stages.
Fully browser-native: No Node, no server, just JS + Web Crypto + Helia.

 
 
 
This is modular: you can expand it to all open-source datasets, run AI embeddings or transformations per shard, and have a fully decentralized, verifiable knowledge base in-browser.


---

# ✅ Solavia v8 — Deterministic AI Runtime

### *Merkle Provenance · Snapshots · Cryptographic Signatures*

Solavia is a deterministic execution runtime for building verifiable AI or data transformation pipelines.

Every pipeline run produces:

* **Stage-level provenance**
* **SHA-256 hashing of input/output**
* **A Merkle tree of all outputs**
* **Optional cryptographic signature**

> Think: *AI execution that can be proven and verified like a blockchain transaction.*

---

## ✨ Features

| Feature                   | Description                            |
| ------------------------- | -------------------------------------- |
| ✅ Deterministic execution | Everything seeded and reproducible     |
| ✅ Stage provenance        | Every step logs its input/output hash  |
| ✅ Merkle tree             | Computes Merkle Root of pipeline       |
| ✅ Proof export            | JSON proof users can inspect or audit  |
| ✅ Digital signatures      | Sign proof using RSA/ECDSA private key |
| ✅ Verification            | Users can verify proof + signature     |
| ✅ Snapshots / rollback    | Save and restore execution state       |
| ✅ Zero dependencies CLI   | No external frameworks                 |

---

## 📦 Installation

> Requires **Node v18+**

```sh
npm install -g solavia
```

Or locally:

```sh
npm install solavia
```

---

## 🚀 Usage

### 1. Create a pipeline script

`pipeline.js`

```js
// examples/pipeline.example.js
import svCore from "../src/solavia-core.js"; // adjust path if needed
const { sha256Hex } = svCore;

export default async function pipeline(sv) {
  console.log("🚀 Starting Solavia example pipeline...");

  // Stage 1: generate deterministic data
  const input = { numbers: [1, 2, 3], seed: sv.config.SEED };
  const output = input.numbers.map(n => n * 2);
  sv.provenance.addStage("DoubleNumbers", input, output, sha256Hex(output));
  console.log("⚠\ninput:", input, "\noutput:", output);

  // Stage 2: compute summary
  const summary = {
    count: output.length,
    sum: output.reduce((a, b) => a + b, 0),
  };
  sv.provenance.addStage("Summarize", output, summary, sha256Hex(summary));
  console.log("⚠\ninput:", output, "\noutput:", summary);

  // Stage 3: pseudo model output
  const result = {
    avg: summary.sum / summary.count,
    seedUsed: sv.config.SEED,
  };
  sv.provenance.addStage("ModelResult", summary, result, sha256Hex(result));
  console.log("⚠\ninput:", summary, "\noutput:", result);

  console.log("✅ Pipeline finished.");
  console.log("🔗 Merkle Root:", sv.provenance.merkleRoot());
}

```

---

### 2. Run it

```sh
solavia run examples/pipeline.js
```

Example output:

```
jameschapman@solavia solavia-npm % solavia run examples/pipeline.js                                                                                                                         
                                                                                                                                                                                            
[SolaVia:INFO] SolaVia started
Info  Running pipeline: pipeline.js
Info  Seed: 1337
🚀 Starting Solavia example pipeline...
⚠
input: { numbers: [ 1, 2, 3 ], seed: 1337 } 
output: [ 2, 4, 6 ]
⚠
input: [ 2, 4, 6 ] 
output: { count: 3, sum: 12 }
⚠
input: { count: 3, sum: 12 } 
output: { avg: 4, seedUsed: 1337 }
✅ Pipeline finished.
🔗 Merkle Root: 10fee41b9017216dc26c288203884d3d9a359ebe5020c0f8722b7089ab11b503
Success Pipeline completed in 4ms
Success Merkle Root: 10fee41b9017216dc26c288203884d3d9a359ebe5020c0f8722b7089ab11b503
```

---

## 🧾 Generate a Merkle Proof

```sh
solavia run examples/pipeline.js --prove
```

Creates:

```
solavia-proof.json
```

Example:

```json
{
  "root": "10fee41b9017216dc26c288203884d3d9a359ebe5020c0f8722b7089ab11b503",
  "stages": [
    {
      "name": "DoubleNumbers",
      "inputHash": "f564638d2bdd6f84fbc34bb3f306ad214408e162ded3e36ad0a54116aa68a2ef",
      "outputHash": "5949a6c45fd2fb2baa3e4576d5255e8752a72cf66402c0e141600be6d402675e",
      "ts": 89464780832077
    },
    {
      "name": "Summarize",
      "inputHash": "5949a6c45fd2fb2baa3e4576d5255e8752a72cf66402c0e141600be6d402675e",
      "outputHash": "3e40387a2031a4bd2537450614c2e883d50fe117dbdd106e580d7a7deb640d8d",
      "ts": 89464780832077
    },
    {
      "name": "ModelResult",
      "inputHash": "3e40387a2031a4bd2537450614c2e883d50fe117dbdd106e580d7a7deb640d8d",
      "outputHash": "03e26f5c84a262a84702fea89456b4dc66a2e62ed9bc9b7835570bd39ab8861a",
      "ts": 89464780832077
    }
  ],
  "seed": 1337,
  "timestamp": "2025-10-29T19:04:33.591Z",
  "version": "8.0.0"
}
```

---

## 🔐 Signing Proofs (Private Key)

### Generate RSA keypair:

```sh
openssl genpkey -algorithm RSA -out key.pem -pkeyopt rsa_keygen_bits:2048
openssl rsa -pubout -in key.pem -out pub.pem
```

### Run pipeline, export proof, sign it:

```sh
jameschapman@solavia solavia-npm % solavia run examples/pipeline.js --prove --sign=key.pem --signature=signature.json                                                                       
```

Created files:

```
solavia-proof.json
signature.json
```

Signature JSON:

```json
{
  "merkleRoot": "10fee41b9017216dc26c288203884d3d9a359ebe5020c0f8722b7089ab11b503",
  "signature": "82ebb99a0ea7214964ef2a019a25e2ac992e539b335cf48fa4a08c7759c521abfab4303f5ec9abedaea9befc2b940d0d074ef624c42b25a9f7aa8bc8b56a31013ba9f87c37fa8087ddea2fb25cfe68b576355043d24d675120a468aca8309a3394993740c2b46198ae9cab0b5bfd147597f5ba9d88ea741bd6003f6bd431ac515ef4e1516698558d6d5a68d4372eebc76bd0eae9aee051bb00fc709da1a8c6dbde9946aca8932f3623e9bb307f2c2965bbf40842038d675dfb43d11f0fb555f124f8986780e07c70f29aeb840f8a5e5a4a1a23dcf7073027c07bb9d9d591f915686cdfe078e0c4b062430b80e829256f998f4090259fda2ab8dcfb973ad30340",
  "canonical": "[{\"input\":{\"numbers\":[1,2,3],\"seed\":1337},\"name\":\"DoubleNumbers\",\"output\":[2,4,6],\"outputHash\":\"5949a6c45fd2fb2baa3e4576d5255e8752a72cf66402c0e141600be6d402675e\",\"ts\":89464780832077},{\"input\":[2,4,6],\"name\":\"Summarize\",\"output\":{\"count\":3,\"sum\":12},\"outputHash\":\"3e40387a2031a4bd2537450614c2e883d50fe117dbdd106e580d7a7deb640d8d\",\"ts\":89464780832077},{\"input\":{\"count\":3,\"sum\":12},\"name\":\"ModelResult\",\"output\":{\"avg\":4,\"seedUsed\":1337},\"outputHash\":\"03e26f5c84a262a84702fea89456b4dc66a2e62ed9bc9b7835570bd39ab8861a\",\"ts\":89464780832077}]"
}
```

---

## ✅ Verify Proof + Signature

```sh
jameschapman@solavia solavia-npm % solavia verify solavia-proof.json  signature.json --pubkey pub.pem                                                                                       
```

Output:

```
Success Merkle proof valid
```

---

## 💾 Snapshots / Rollback

Save current runtime state:

```sh
solavia snapshot "checkpoint-a"
```

Rollback to a previous snapshot via CID:

```sh
solavia rollback bafy...xyz
```

---

## 🧠 Advanced Example (AI + API request)

Example: pipeline with API fetch + embedding hashing.

`agent-pipeline.js`:

```js
export default async function (sv) {
  sv.stage("fetch-joke", async () => {
    const r = await fetch("https://api.chucknorris.io/jokes/random");
    const joke = await r.json();
    return joke.value;
  });

  sv.stage("embed", async (joke) => {
    const vector = await sv.ai.embed(joke); // uses Solavia's deterministic embedding
    return vector;
  });

  sv.stage("rank", async (vector) => {
    return vector.reduce((acc, n) => acc + n, 0);
  });
}
```

Run:

```sh
solavia run src/agent-pipeline.js --seed=1337 --prove --sign=key.pem --signature=signature.json
```

```sh
solavia run src/agent-pipeline.js --seed=1337 --prove --sign=key.pem --signature=signature.json  
```
Output:

```sh                                                                                                                                                                                    [SolaVia:INFO] SolaVia started
Info  Running pipeline: agent-pipeline.js
Info  Seed: 1337
Pipeline finished. Merkle root: 9dd1dbd8f194496192137cb15fed74511f49346175f3f31c0704eb37d1482b20
Success Pipeline completed in 455ms
Success Merkle Root: 9dd1dbd8f194496192137cb15fed74511f49346175f3f31c0704eb37d1482b20
Success Proof exported: solavia-proof.json
Success Signed proof: signature.json

```

---

## 🧩 CLI Reference

```
solavia <command> [options]

Commands:
  run <file.js>       Run a pipeline script
  verify [proof]      Verify Merkle proof + signature
  snapshot [name]     Create a named snapshot
  rollback <cid>      Restore a snapshot
  help                Show help

Options:
  --seed=1337         Deterministic seed
  --prove=file.json   Export Merkle proof
  --sign=key.pem      Sign proof with private key
  --signature=file    Output file for signature JSON
  --pubkey=file       Public key for verification
```

---

## 🧠 Why Merkle Proofs?

Because they create **tamper evidence**.

Even if someone modifies *one stage output*, the Merkle root changes — and verification fails.

---

## 🏁 License

Solavia Runtime — Open Source (Non‑Commercial)
✅ Free for personal, academic, research
❌ Commercial use requires paid license
© 2025 James Chapman llc.
EMAIL='iconoclastdao@gmail.com'


---

---

# ✅ Solavia v8 — Deterministic AI Runtime

### *Merkle Provenance · Snapshots · Cryptographic Signatures*

Solavia is a deterministic execution runtime for building verifiable AI or data transformation pipelines.

Every pipeline run produces:

* **Stage-level provenance**
* **SHA-256 hashing of input/output**
* **A Merkle tree of all outputs**
* **Optional cryptographic signature**

> Think: *AI execution that can be proven and verified like a blockchain transaction.*

---

## ✨ Features

| Feature                   | Description                            |
| ------------------------- | -------------------------------------- |
| ✅ Deterministic execution | Everything seeded and reproducible     |
| ✅ Stage provenance        | Every step logs its input/output hash  |
| ✅ Merkle tree             | Computes Merkle Root of pipeline       |
| ✅ Proof export            | JSON proof users can inspect or audit  |
| ✅ Digital signatures      | Sign proof using RSA/ECDSA private key |
| ✅ Verification            | Users can verify proof + signature     |
| ✅ Snapshots / rollback    | Save and restore execution state       |
| ✅ Zero dependencies CLI   | No external frameworks                 |

---

## 📦 Installation

> Requires **Node v18+**

```sh
npm install -g solavia
```

Or locally:

```sh
npm install solavia
```

---

## 🚀 Usage

### 1. Create a pipeline script

`pipeline.js`

```js
// examples/pipeline.example.js
import svCore from "../src/solavia-core.js"; // adjust path if needed
const { sha256Hex } = svCore;

export default async function pipeline(sv) {
  console.log("🚀 Starting Solavia example pipeline...");

  // Stage 1: generate deterministic data
  const input = { numbers: [1, 2, 3], seed: sv.config.SEED };
  const output = input.numbers.map(n => n * 2);
  sv.provenance.addStage("DoubleNumbers", input, output, sha256Hex(output));
  console.log("⚠\ninput:", input, "\noutput:", output);

  // Stage 2: compute summary
  const summary = {
    count: output.length,
    sum: output.reduce((a, b) => a + b, 0),
  };
  sv.provenance.addStage("Summarize", output, summary, sha256Hex(summary));
  console.log("⚠\ninput:", output, "\noutput:", summary);

  // Stage 3: pseudo model output
  const result = {
    avg: summary.sum / summary.count,
    seedUsed: sv.config.SEED,
  };
  sv.provenance.addStage("ModelResult", summary, result, sha256Hex(result));
  console.log("⚠\ninput:", summary, "\noutput:", result);

  console.log("✅ Pipeline finished.");
  console.log("🔗 Merkle Root:", sv.provenance.merkleRoot());
}

```

---

### 2. Run it

```sh
solavia run examples/pipeline.js
```

Example output:

```
jameschapman@solavia solavia-npm % solavia run examples/pipeline.js                                                                                                                         
                                                                                                                                                                                            
[SolaVia:INFO] SolaVia started
Info  Running pipeline: pipeline.js
Info  Seed: 1337
🚀 Starting Solavia example pipeline...
⚠
input: { numbers: [ 1, 2, 3 ], seed: 1337 } 
output: [ 2, 4, 6 ]
⚠
input: [ 2, 4, 6 ] 
output: { count: 3, sum: 12 }
⚠
input: { count: 3, sum: 12 } 
output: { avg: 4, seedUsed: 1337 }
✅ Pipeline finished.
🔗 Merkle Root: 10fee41b9017216dc26c288203884d3d9a359ebe5020c0f8722b7089ab11b503
Success Pipeline completed in 4ms
Success Merkle Root: 10fee41b9017216dc26c288203884d3d9a359ebe5020c0f8722b7089ab11b503
```

---

## 🧾 Generate a Merkle Proof

```sh
solavia run examples/pipeline.js --prove
```

Creates:

```
solavia-proof.json
```

Example:

```json
{
  "root": "10fee41b9017216dc26c288203884d3d9a359ebe5020c0f8722b7089ab11b503",
  "stages": [
    {
      "name": "DoubleNumbers",
      "inputHash": "f564638d2bdd6f84fbc34bb3f306ad214408e162ded3e36ad0a54116aa68a2ef",
      "outputHash": "5949a6c45fd2fb2baa3e4576d5255e8752a72cf66402c0e141600be6d402675e",
      "ts": 89464780832077
    },
    {
      "name": "Summarize",
      "inputHash": "5949a6c45fd2fb2baa3e4576d5255e8752a72cf66402c0e141600be6d402675e",
      "outputHash": "3e40387a2031a4bd2537450614c2e883d50fe117dbdd106e580d7a7deb640d8d",
      "ts": 89464780832077
    },
    {
      "name": "ModelResult",
      "inputHash": "3e40387a2031a4bd2537450614c2e883d50fe117dbdd106e580d7a7deb640d8d",
      "outputHash": "03e26f5c84a262a84702fea89456b4dc66a2e62ed9bc9b7835570bd39ab8861a",
      "ts": 89464780832077
    }
  ],
  "seed": 1337,
  "timestamp": "2025-10-29T19:04:33.591Z",
  "version": "8.0.0"
}
```

---

## 🔐 Signing Proofs (Private Key)

### Generate RSA keypair:

```sh
openssl genpkey -algorithm RSA -out key.pem -pkeyopt rsa_keygen_bits:2048
openssl rsa -pubout -in key.pem -out pub.pem
```

### Run pipeline, export proof, sign it:

```sh
jameschapman@solavia solavia-npm % solavia run examples/pipeline.js --prove --sign=key.pem --signature=signature.json                                                                       
```

Created files:

```
solavia-proof.json
signature.json
```

Signature JSON:

```json
{
  "merkleRoot": "10fee41b9017216dc26c288203884d3d9a359ebe5020c0f8722b7089ab11b503",
  "signature": "82ebb99a0ea7214964ef2a019a25e2ac992e539b335cf48fa4a08c7759c521abfab4303f5ec9abedaea9befc2b940d0d074ef624c42b25a9f7aa8bc8b56a31013ba9f87c37fa8087ddea2fb25cfe68b576355043d24d675120a468aca8309a3394993740c2b46198ae9cab0b5bfd147597f5ba9d88ea741bd6003f6bd431ac515ef4e1516698558d6d5a68d4372eebc76bd0eae9aee051bb00fc709da1a8c6dbde9946aca8932f3623e9bb307f2c2965bbf40842038d675dfb43d11f0fb555f124f8986780e07c70f29aeb840f8a5e5a4a1a23dcf7073027c07bb9d9d591f915686cdfe078e0c4b062430b80e829256f998f4090259fda2ab8dcfb973ad30340",
  "canonical": "[{\"input\":{\"numbers\":[1,2,3],\"seed\":1337},\"name\":\"DoubleNumbers\",\"output\":[2,4,6],\"outputHash\":\"5949a6c45fd2fb2baa3e4576d5255e8752a72cf66402c0e141600be6d402675e\",\"ts\":89464780832077},{\"input\":[2,4,6],\"name\":\"Summarize\",\"output\":{\"count\":3,\"sum\":12},\"outputHash\":\"3e40387a2031a4bd2537450614c2e883d50fe117dbdd106e580d7a7deb640d8d\",\"ts\":89464780832077},{\"input\":{\"count\":3,\"sum\":12},\"name\":\"ModelResult\",\"output\":{\"avg\":4,\"seedUsed\":1337},\"outputHash\":\"03e26f5c84a262a84702fea89456b4dc66a2e62ed9bc9b7835570bd39ab8861a\",\"ts\":89464780832077}]"
}
```

---

## ✅ Verify Proof + Signature

```sh
jameschapman@solavia solavia-npm % solavia verify solavia-proof.json  signature.json --pubkey pub.pem                                                                                       
```

Output:

```
Success Merkle proof valid
```

---

## 💾 Snapshots / Rollback

Save current runtime state:

```sh
solavia snapshot "checkpoint-a"
```

Rollback to a previous snapshot via CID:

```sh
solavia rollback bafy...xyz
```

---

## 🧠 Advanced Example (AI + API request)

Example: pipeline with API fetch + embedding hashing.

`agent-pipeline.js`:

```js
export default async function (sv) {
  sv.stage("fetch-joke", async () => {
    const r = await fetch("https://api.chucknorris.io/jokes/random");
    const joke = await r.json();
    return joke.value;
  });

  sv.stage("embed", async (joke) => {
    const vector = await sv.ai.embed(joke); // uses Solavia's deterministic embedding
    return vector;
  });

  sv.stage("rank", async (vector) => {
    return vector.reduce((acc, n) => acc + n, 0);
  });
}
```

Run:

```sh
solavia run src/agent-pipeline.js --seed=1337 --prove --sign=key.pem --signature=signature.json
```

```sh
solavia run src/agent-pipeline.js --seed=1337 --prove --sign=key.pem --signature=signature.json  
```
Output:

```sh
Info  Running pipeline: agent-pipeline.js
Info  Seed: 1337
Pipeline finished. Merkle root: 9dd1dbd8f194496192137cb15fed74511f49346175f3f31c0704eb37d1482b20
Success Pipeline completed in 455ms
Success Merkle Root: 9dd1dbd8f194496192137cb15fed74511f49346175f3f31c0704eb37d1482b20
Success Proof exported: solavia-proof.json
Success Signed proof: signature.json

```

---

## 🧩 CLI Reference

```
solavia <command> [options]

Commands:
  run <file.js>       Run a pipeline script
  verify [proof]      Verify Merkle proof + signature
  snapshot [name]     Create a named snapshot
  rollback <cid>      Restore a snapshot
  help                Show help

Options:
  --seed=1337         Deterministic seed
  --prove=file.json   Export Merkle proof
  --sign=key.pem      Sign proof with private key
  --signature=file    Output file for signature JSON
  --pubkey=file       Public key for verification
```

---

## 🧠 Why Merkle Proofs?

Because they create **tamper evidence**.

Even if someone modifies *one stage output*, the Merkle root changes — and verification fails.

---

## 🏁 License

Solavia Runtime — Open Source (Non‑Commercial)
✅ Free for personal, academic, research
❌ Commercial use requires paid license
© 2025 James Chapman llc.
EMAIL='iconoclastdao@gmail.com'


---


---

# ✅ Solavia v8 — Deterministic AI Runtime

### *Merkle Provenance · Snapshots · Cryptographic Signatures*

Solavia is a deterministic execution runtime for building verifiable AI or data transformation pipelines.

Every pipeline run produces:

* **Stage-level provenance**
* **SHA-256 hashing of input/output**
* **A Merkle tree of all outputs**
* **Optional cryptographic signature**

> Think: *AI execution that can be proven and verified like a blockchain transaction.*

---

## ✨ Features

| Feature                   | Description                            |
| ------------------------- | -------------------------------------- |
| ✅ Deterministic execution | Everything seeded and reproducible     |
| ✅ Stage provenance        | Every step logs its input/output hash  |
| ✅ Merkle tree             | Computes Merkle Root of pipeline       |
| ✅ Proof export            | JSON proof users can inspect or audit  |
| ✅ Digital signatures      | Sign proof using RSA/ECDSA private key |
| ✅ Verification            | Users can verify proof + signature     |
| ✅ Snapshots / rollback    | Save and restore execution state       |
| ✅ Zero dependencies CLI   | No external frameworks                 |

---

## 📦 Installation

> Requires **Node v18+**

```sh
npm install -g solavia
```

Or locally:

```sh
npm install solavia
```

---

## 🚀 Usage

### 1. Create a pipeline script

`pipeline.js`

```js
// examples/pipeline.example.js
import svCore from "../src/solavia-core.js"; // adjust path if needed
const { sha256Hex } = svCore;

export default async function pipeline(sv) {
  console.log("🚀 Starting Solavia example pipeline...");

  // Stage 1: generate deterministic data
  const input = { numbers: [1, 2, 3], seed: sv.config.SEED };
  const output = input.numbers.map(n => n * 2);
  sv.provenance.addStage("DoubleNumbers", input, output, sha256Hex(output));
  console.log("⚠\ninput:", input, "\noutput:", output);

  // Stage 2: compute summary
  const summary = {
    count: output.length,
    sum: output.reduce((a, b) => a + b, 0),
  };
  sv.provenance.addStage("Summarize", output, summary, sha256Hex(summary));
  console.log("⚠\ninput:", output, "\noutput:", summary);

  // Stage 3: pseudo model output
  const result = {
    avg: summary.sum / summary.count,
    seedUsed: sv.config.SEED,
  };
  sv.provenance.addStage("ModelResult", summary, result, sha256Hex(result));
  console.log("⚠\ninput:", summary, "\noutput:", result);

  console.log("✅ Pipeline finished.");
  console.log("🔗 Merkle Root:", sv.provenance.merkleRoot());
}

```

---

### 2. Run it

```sh
solavia run examples/pipeline.js
```

Example output:

```
jameschapman@solavia solavia-npm % solavia run examples/pipeline.js                                                                                                                         
                                                                                                                                                                                            
[SolaVia:INFO] SolaVia started
Info  Running pipeline: pipeline.js
Info  Seed: 1337
🚀 Starting Solavia example pipeline...
⚠
input: { numbers: [ 1, 2, 3 ], seed: 1337 } 
output: [ 2, 4, 6 ]
⚠
input: [ 2, 4, 6 ] 
output: { count: 3, sum: 12 }
⚠
input: { count: 3, sum: 12 } 
output: { avg: 4, seedUsed: 1337 }
✅ Pipeline finished.
🔗 Merkle Root: 10fee41b9017216dc26c288203884d3d9a359ebe5020c0f8722b7089ab11b503
Success Pipeline completed in 4ms
Success Merkle Root: 10fee41b9017216dc26c288203884d3d9a359ebe5020c0f8722b7089ab11b503
```

---

## 🧾 Generate a Merkle Proof

```sh
solavia run examples/pipeline.js --prove
```

Creates:

```
solavia-proof.json
```

Example:

```json
{
  "root": "10fee41b9017216dc26c288203884d3d9a359ebe5020c0f8722b7089ab11b503",
  "stages": [
    {
      "name": "DoubleNumbers",
      "inputHash": "f564638d2bdd6f84fbc34bb3f306ad214408e162ded3e36ad0a54116aa68a2ef",
      "outputHash": "5949a6c45fd2fb2baa3e4576d5255e8752a72cf66402c0e141600be6d402675e",
      "ts": 89464780832077
    },
    {
      "name": "Summarize",
      "inputHash": "5949a6c45fd2fb2baa3e4576d5255e8752a72cf66402c0e141600be6d402675e",
      "outputHash": "3e40387a2031a4bd2537450614c2e883d50fe117dbdd106e580d7a7deb640d8d",
      "ts": 89464780832077
    },
    {
      "name": "ModelResult",
      "inputHash": "3e40387a2031a4bd2537450614c2e883d50fe117dbdd106e580d7a7deb640d8d",
      "outputHash": "03e26f5c84a262a84702fea89456b4dc66a2e62ed9bc9b7835570bd39ab8861a",
      "ts": 89464780832077
    }
  ],
  "seed": 1337,
  "timestamp": "2025-10-29T19:04:33.591Z",
  "version": "8.0.0"
}
```

---

## 🔐 Signing Proofs (Private Key)

### Generate RSA keypair:

```sh
openssl genpkey -algorithm RSA -out key.pem -pkeyopt rsa_keygen_bits:2048
openssl rsa -pubout -in key.pem -out pub.pem
```

### Run pipeline, export proof, sign it:

```sh
jameschapman@solavia solavia-npm % solavia run examples/pipeline.js --prove --sign=key.pem --signature=signature.json                                                                       
```

Created files:

```
solavia-proof.json
signature.json
```

Signature JSON:

```json
{
  "merkleRoot": "10fee41b9017216dc26c288203884d3d9a359ebe5020c0f8722b7089ab11b503",
  "signature": "82ebb99a0ea7214964ef2a019a25e2ac992e539b335cf48fa4a08c7759c521abfab4303f5ec9abedaea9befc2b940d0d074ef624c42b25a9f7aa8bc8b56a31013ba9f87c37fa8087ddea2fb25cfe68b576355043d24d675120a468aca8309a3394993740c2b46198ae9cab0b5bfd147597f5ba9d88ea741bd6003f6bd431ac515ef4e1516698558d6d5a68d4372eebc76bd0eae9aee051bb00fc709da1a8c6dbde9946aca8932f3623e9bb307f2c2965bbf40842038d675dfb43d11f0fb555f124f8986780e07c70f29aeb840f8a5e5a4a1a23dcf7073027c07bb9d9d591f915686cdfe078e0c4b062430b80e829256f998f4090259fda2ab8dcfb973ad30340",
  "canonical": "[{\"input\":{\"numbers\":[1,2,3],\"seed\":1337},\"name\":\"DoubleNumbers\",\"output\":[2,4,6],\"outputHash\":\"5949a6c45fd2fb2baa3e4576d5255e8752a72cf66402c0e141600be6d402675e\",\"ts\":89464780832077},{\"input\":[2,4,6],\"name\":\"Summarize\",\"output\":{\"count\":3,\"sum\":12},\"outputHash\":\"3e40387a2031a4bd2537450614c2e883d50fe117dbdd106e580d7a7deb640d8d\",\"ts\":89464780832077},{\"input\":{\"count\":3,\"sum\":12},\"name\":\"ModelResult\",\"output\":{\"avg\":4,\"seedUsed\":1337},\"outputHash\":\"03e26f5c84a262a84702fea89456b4dc66a2e62ed9bc9b7835570bd39ab8861a\",\"ts\":89464780832077}]"
}
```

---

## ✅ Verify Proof + Signature

```sh
jameschapman@solavia solavia-npm % solavia verify solavia-proof.json  signature.json --pubkey pub.pem                                                                                       
```

Output:

```
Success Merkle proof valid
```

---

## 💾 Snapshots / Rollback

Save current runtime state:

```sh
solavia snapshot "checkpoint-a"
```

Rollback to a previous snapshot via CID:

```sh
solavia rollback bafy...xyz
```

---

## 🧠 Advanced Example (AI + API request)

Example: pipeline with API fetch + embedding hashing.

`agent-pipeline.js`:

```js
export default async function (sv) {
  sv.stage("fetch-joke", async () => {
    const r = await fetch("https://api.chucknorris.io/jokes/random");
    const joke = await r.json();
    return joke.value;
  });

  sv.stage("embed", async (joke) => {
    const vector = await sv.ai.embed(joke); // uses Solavia's deterministic embedding
    return vector;
  });

  sv.stage("rank", async (vector) => {
    return vector.reduce((acc, n) => acc + n, 0);
  });
}
```

Run:

```sh
solavia run src/agent-pipeline.js --seed=1337 --prove --sign=key.pem --signature=signature.json
```

```sh
solavia run src/agent-pipeline.js --seed=1337 --prove --sign=key.pem --signature=signature.json  
```
Output:

```sh
Info  Running pipeline: agent-pipeline.js
Info  Seed: 1337
Pipeline finished. Merkle root: 9dd1dbd8f194496192137cb15fed74511f49346175f3f31c0704eb37d1482b20
Success Pipeline completed in 455ms
Success Merkle Root: 9dd1dbd8f194496192137cb15fed74511f49346175f3f31c0704eb37d1482b20
Success Proof exported: solavia-proof.json
Success Signed proof: signature.json

```

---

## 🧩 CLI Reference

```
solavia <command> [options]

Commands:
  run <file.js>       Run a pipeline script
  verify [proof]      Verify Merkle proof + signature
  snapshot [name]     Create a named snapshot
  rollback <cid>      Restore a snapshot
  help                Show help

Options:
  --seed=1337         Deterministic seed
  --prove=file.json   Export Merkle proof
  --sign=key.pem      Sign proof with private key
  --signature=file    Output file for signature JSON
  --pubkey=file       Public key for verification
```

---

## 🧠 Why Merkle Proofs?

Because they create **tamper evidence**.

Even if someone modifies *one stage output*, the Merkle root changes — and verification fails.

---

## 🏁 License

Solavia Runtime — Open Source (Non‑Commercial)
✅ Free for personal, academic, research
❌ Commercial use requires paid license
© 2025 James Chapman llc.
EMAIL='iconoclastdao@gmail.com'


---
